{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf #tensorflow 1.14.0\n",
    "tf.enable_eager_execution()\n",
    "print(tf.executing_eagerly())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import chakin\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gzip\n",
    "from gensim import models as gmodel\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotation_file = '/home/nilay/Documents/coco/captions/annotations/captions_train2014.json'\n",
    "train_incep_path = '/home/nilay/Documents/coco/train_incep/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82783\n"
     ]
    }
   ],
   "source": [
    "train_incep_paths = glob(train_incep_path+'*/*npy')\n",
    "\n",
    "print(len(train_incep_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nilay/Documents/coco/train_incep/9/COCO_train2014_000000581204.npy',\n",
       " '/home/nilay/Documents/coco/train_incep/9/COCO_train2014_000000581310.npy',\n",
       " '/home/nilay/Documents/coco/train_incep/9/COCO_train2014_000000581396.npy',\n",
       " '/home/nilay/Documents/coco/train_incep/9/COCO_train2014_000000581507.npy',\n",
       " '/home/nilay/Documents/coco/train_incep/9/COCO_train2014_000000581667.npy',\n",
       " '/home/nilay/Documents/coco/train_incep/9/COCO_train2014_000000581686.npy',\n",
       " '/home/nilay/Documents/coco/train_incep/9/COCO_train2014_000000581697.npy',\n",
       " '/home/nilay/Documents/coco/train_incep/9/COCO_train2014_000000581708.npy',\n",
       " '/home/nilay/Documents/coco/train_incep/9/COCO_train2014_000000581719.npy',\n",
       " '/home/nilay/Documents/coco/train_incep/9/COCO_train2014_000000581882.npy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_incep_paths.sort()\n",
    "train_incep_paths[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {}\n",
    "for f in train_incep_paths:\n",
    "    train_dict[int(f[56:-4])] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "train_paths = []\n",
    "for key in train_dict:\n",
    "    train_ids.append(key)\n",
    "    train_paths.append(train_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "414113it [00:00, 928392.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414113\n",
      "82783\n"
     ]
    }
   ],
   "source": [
    "with open(train_annotation_file, 'r') as f:\n",
    "    train_annotations = json.load(f)\n",
    "\n",
    "train_captions = []\n",
    "train_img_paths = []\n",
    "\n",
    "for i,annot in tqdm(enumerate(train_annotations['annotations'])):\n",
    "    caption = '<start> ' + annot['caption'] + ' <end>'\n",
    "    image_id = annot['image_id']\n",
    "    image_path = train_dict[image_id]\n",
    "\n",
    "    train_img_paths.append(image_path)\n",
    "    train_captions.append(caption)\n",
    "\n",
    "train_captions, train_img_paths = shuffle(train_captions,\n",
    "                                          train_img_paths,\n",
    "                                          random_state=1)\n",
    "\n",
    "print(len(train_img_paths))\n",
    "print(len(list(set(train_img_paths))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_word_map = pd.read_csv('/home/nilay/Documents/coco/row_word_map.csv')\n",
    "embed = np.load('/home/nilay/Documents/coco/embed.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23899, 3)\n",
      "(23899, 300)\n"
     ]
    }
   ],
   "source": [
    "print(row_word_map.shape)\n",
    "print(embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>row</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;start&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  row     word\n",
       "0           0    0        _\n",
       "1           1    1        a\n",
       "2           2    2  <start>\n",
       "3           3    3    <end>\n",
       "4           4    4        ."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_word_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dict = {}\n",
    "for i,row in row_word_map.iterrows():\n",
    "    row = row.values\n",
    "    if row[2]!='_':\n",
    "        embed_dict[row[2]]=row[1]\n",
    "embed_dict['<pad>'] = 0\n",
    "embed_dict['<unk>'] = len(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = pd.read_csv('/home/nilay/Documents/coco/corec_map1.csv')\n",
    "map_dict = {}\n",
    "for i,row in map_df.iterrows():\n",
    "    row = row.values\n",
    "    map_dict[row[0]] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"!#$%&()'*+,-./:;=?@[\\\\]^_`{|}~\\t\\n\"+'\"',)\n",
    "tokenizer.fit_on_texts(train_captions)\n",
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "train_seqs = tokenizer.texts_to_sequences(train_captions)\n",
    "\n",
    "train_text = tokenizer.sequences_to_texts(train_seqs)\n",
    "\n",
    "train_text_corec = []\n",
    "for line in train_text:\n",
    "    line = ' '.join([map_dict[l] if l in map_dict else l for l in line.split()])\n",
    "    train_text_corec.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [00:02<00:00, 203457.68it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embed = []\n",
    "for line in tqdm(train_text_corec):\n",
    "    line = [embed_dict[l] if l in embed_dict else embed_dict['<unk>'] for l in line.split()]\n",
    "    train_embed.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23899, 300)\n",
      "(23900, 300)\n"
     ]
    }
   ],
   "source": [
    "print(embed.shape)\n",
    "embed[0] = np.zeros((1,300))\n",
    "z = np.random.rand(1,300)\n",
    "embed = np.array(embed.tolist()+z.tolist())\n",
    "print(embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "max_len = calc_max_length(train_seqs)\n",
    "train_seqs_pad = tf.keras.preprocessing.sequence.pad_sequences(train_embed, padding='post',maxlen=max_len,dtype='int64')\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 2000\n",
    "embedding_dim = 300\n",
    "units = 600\n",
    "vocab_size = 23900\n",
    "num_steps = len(train_img_paths) // BATCH_SIZE\n",
    "features_shape = 2048\n",
    "attention_features_shape = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(img_name, cap):\n",
    "    img_tensor = np.load(img_name.decode('utf-8'))\n",
    "    return img_tensor, cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_img_paths, train_seqs_pad))\n",
    "\n",
    "# Use map to load the numpy files in parallel\n",
    "dataset = dataset.map(lambda item1, item2: tf.numpy_function(\n",
    "          map_func, [item1, item2], [tf.float32, tf.int64]),\n",
    "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Shuffle and batch\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, embedding_dim, units):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.fc = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.W_h = tf.keras.layers.Dense(self.units)\n",
    "        self.W_c = tf.keras.layers.Dense(self.units)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.bn(x)\n",
    "        x_mean = tf.reduce_mean(x,1)\n",
    "        h_state = self.W_h(x_mean)\n",
    "        h_state = tf.nn.tanh(h_state)\n",
    "        c_state = self.W_c(x_mean)\n",
    "        c_state = tf.nn.tanh(c_state)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x ,c_state,h_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units, vocab_size):\n",
    "        super(RNN_Decoder, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim,embeddings_initializer=tf.keras.initializers.Constant(embed))\n",
    "        self.lstm = tf.keras.layers.LSTMCell(self.units)\n",
    "        self.fc1 = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.fc2 = tf.keras.layers.Dense(embedding_dim,use_bias=False)\n",
    "        self.fc3 = tf.keras.layers.Dense(vocab_size)\n",
    "        self.fc_beta = tf.keras.layers.Dense(1)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.units)\n",
    "\n",
    "    def call(self, x, features, c_state, h_state):\n",
    "        context_vector, attention_weights = self.attention(features, h_state)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        beta = self.fc_beta(h_state)\n",
    "        beta = tf.nn.sigmoid(beta)\n",
    "        context_vector = tf.multiply(beta, context_vector, name='selected_context')\n",
    "\n",
    "        x_in = tf.concat([x,context_vector], axis=1)\n",
    "\n",
    "        output,[c_state,h_state] = self.lstm(x,states=[c_state,h_state])\n",
    "\n",
    "        h_state = tf.nn.dropout(h_state,0.5)\n",
    "        W_h = self.fc1(h_state)\n",
    "        W_context = self.fc2(context_vector)\n",
    "        h_logits = W_h + W_context + x\n",
    "        h_logits = tf.nn.tanh(h_logits)\n",
    "        h_logits = tf.nn.dropout(h_logits,0.5)\n",
    "        out_logits = self.fc3(h_logits)\n",
    "\n",
    "        return out_logits, c_state, h_state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder(embedding_dim, units)\n",
    "decoder = RNN_Decoder(embedding_dim, units, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/nilay/Documents/coco/checkpoints/train'\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer = optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(img_tensor, target, epoch):\n",
    "    loss = 0\n",
    "\n",
    "    dec_input = tf.convert_to_tensor([tokenizer.word_index['<start>']] * img_tensor.shape[0], 1)\n",
    "    limit = 0.8 - (epoch/50)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        features, c_state, h_state = encoder(img_tensor)\n",
    "        alpha_list = []\n",
    "        alpha_c = 0.01\n",
    "\n",
    "        for i in range(1, target.shape[1]):\n",
    "            predictions, c_state, h_state, attention_weights = decoder(dec_input, features, c_state, h_state)\n",
    "            alpha_list.append(attention_weights)\n",
    "\n",
    "            loss += loss_function(target[:, i], predictions)\n",
    "            predicted_id = tf.argmax(predictions,-1)\n",
    "\n",
    "            dec_input = tf.cond(tf.random.uniform((1,))<limit,\n",
    "                  lambda:tf.convert_to_tensor(target[:, i], dtype=tf.int64),\n",
    "                  lambda:tf.convert_to_tensor(predicted_id, dtype=tf.int64))\n",
    "\n",
    "        alphas = tf.stack(alpha_list)\n",
    "        alphas = tf.transpose(alphas, (1, 0, 2,3)) \n",
    "        alphas_all = tf.reduce_sum(alphas, 1)   \n",
    "        alpha_reg = tf.reduce_sum((52./64 - alphas_all) ** 2,1)\n",
    "        alpha_reg = alpha_c * tf.reduce_mean(alpha_reg)\n",
    "        loss += alpha_reg\n",
    "\n",
    "    total_loss = (loss / int(target.shape[1]))\n",
    "\n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nilay/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1 Batch 0 Loss 2.2266\n",
      "Epoch 1 Batch 50 Loss 1.1010\n",
      "Epoch 1 Batch 100 Loss 1.1060\n",
      "Epoch 1 Batch 150 Loss 1.0141\n",
      "Epoch 1 Batch 200 Loss 1.0000\n",
      "Epoch 1 Batch 250 Loss 0.9029\n",
      "Epoch 1 Batch 300 Loss 0.9089\n",
      "Epoch 1 Batch 350 Loss 0.9001\n",
      "Epoch 1 Batch 400 Loss 0.8689\n",
      "Epoch 1 Batch 450 Loss 0.7770\n",
      "Epoch 1 Batch 500 Loss 0.8133\n",
      "Epoch 1 Batch 550 Loss 0.9422\n",
      "Epoch 1 Batch 600 Loss 0.8348\n",
      "Epoch 1 Batch 650 Loss 0.8151\n",
      "Epoch 1 Batch 700 Loss 0.7677\n",
      "Epoch 1 Batch 750 Loss 0.8592\n",
      "Epoch 1 Batch 800 Loss 0.7802\n",
      "Epoch 1 Batch 850 Loss 0.7044\n",
      "Epoch 1 Batch 900 Loss 0.8269\n",
      "Epoch 1 Batch 950 Loss 0.8568\n",
      "Epoch 1 Batch 1000 Loss 0.8081\n",
      "Epoch 1 Batch 1050 Loss 0.7512\n",
      "Epoch 1 Batch 1100 Loss 0.7674\n",
      "Epoch 1 Batch 1150 Loss 0.8011\n",
      "Epoch 1 Batch 1200 Loss 0.7436\n",
      "Epoch 1 Batch 1250 Loss 0.8322\n",
      "Epoch 1 Batch 1300 Loss 0.7310\n",
      "Epoch 1 Batch 1350 Loss 0.9121\n",
      "Epoch 1 Batch 1400 Loss 0.7881\n",
      "Epoch 1 Batch 1450 Loss 0.7965\n",
      "Epoch 1 Batch 1500 Loss 0.8314\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "        batch_loss, t_loss = train_step(img_tensor, target, epoch)\n",
    "        total_loss += t_loss\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "            epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))\n",
    "          \n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "\n",
    "    ckpt_manager.save()\n",
    "\n",
    "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                         total_loss/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
